{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Add noise to audio files')\n",
    "parser.add_argument('--data_split', type=str, default=\"/old_scratch/bbjs/ylu3/SpeechCLIP/data/flickr/flickr_dev_sampled.csv\")\n",
    "parser.add_argument(\"--data_root\", type=str, default=\"/old_scratch/bbjs/ylu3/SpeechCLIP/data/flickr/flickr_audio/wavs\")\n",
    "parser.add_argument('--output_dir', type=str, default=\"/old_scratch/bbjs/ylu3/tmp/flickr/noisy_dev_sampled\")\n",
    "parser.add_argument('--snr', type=int, default=20)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_file = args.data_split\n",
    "output_dir = f\"{args.output_dir}_{args.snr}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "data = []\n",
    "with open(data_file, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "for i, d in tqdm(enumerate(data[1:])):\n",
    "    input_path = f\"{args.data_root}/{d[2]}\"\n",
    "    if os.path.exists(input_path):\n",
    "        waveform, sample_rate = torchaudio.load(input_path)\n",
    "        noise = torch.randn_like(waveform)\n",
    "        add_noise = T.AddNoise()\n",
    "        noisy_waveform = add_noise(waveform, noise, snr=torch.tensor([args.snr]))\n",
    "        torchaudio.save(f\"{output_dir}/{d[2]}\", noisy_waveform, sample_rate)\n",
    "    else:\n",
    "        print(f\"{input_path} does not exist\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
